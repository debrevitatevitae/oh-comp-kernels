{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training RBF and classifying the binary Iris dataset\n",
    "For visualization purposes in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ohqk.data import LabelledDataset\n",
    "from ohqk.kta_classical import KernelTargetAlignmentLoss, rbf_kernel\n",
    "from ohqk.project_directories import GRAPHICS_DIR\n",
    "from ohqk.train import train\n",
    "from ohqk.utils import relabel_to_m1p1, running_average_filter\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "# make the y axis invisible\n",
    "plt.rcParams[\"ytick.left\"] = False\n",
    "plt.rcParams[\"ytick.labelleft\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and rescale the data\n",
    "Note that here the kernel training is done on the full dataset and the classifier selection/training/testing splits the data first. For the paper results the split happens already before kernel training (which is also good ML practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X = X[y < 2]\n",
    "y = relabel_to_m1p1(y[y < 2])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "ds = LabelledDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_checkpoints = 50\n",
    "batch_size = 50\n",
    "lr = 1e-1\n",
    "gamma = 10 * torch.rand(1)  # initial gamma\n",
    "gamma.requires_grad = True\n",
    "\n",
    "dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "opt = torch.optim.Adam([gamma], lr)\n",
    "loss_function = KernelTargetAlignmentLoss(rbf_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial gamma:\", gamma.item())\n",
    "# train the model\n",
    "trained_gamma, losses = train(\n",
    "    gamma,\n",
    "    loss_function,\n",
    "    opt,\n",
    "    num_epochs,\n",
    "    dl,\n",
    "    num_checkpoints=num_checkpoints,\n",
    ")\n",
    "print(\"trained gamma:\", trained_gamma.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_losses = running_average_filter(losses, factor=0.6)\n",
    "plt.plot([-s for s in smooth_losses])  # negative sign for kta\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"KTA\")\n",
    "plt.savefig(GRAPHICS_DIR / \"rbf_kta_opt_iris.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"C\": [0.1, 1, 10, 100], }\n",
    "svc = SVC(kernel=\"rbf\", gamma=trained_gamma.item())\n",
    "\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, verbose=3, n_jobs=-1, scoring=\"accuracy\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best C\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ohqk.model_testing import produce_clf_learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fractions = np.linspace(0.1, 1, 10)\n",
    "_, test_scores = produce_clf_learning_curve(\n",
    "    grid_search.best_estimator_, X_train, X_test, y_train, y_test, train_fractions=train_fractions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=train_fractions, y=test_scores)\n",
    "plt.xticks(ticks=np.arange(0, 10, 2), labels=[f\"{t:.0%}\" for t in train_fractions[::2]])\n",
    "plt.xlabel(\"train fraction\")\n",
    "plt.ylabel(\"test score\")\n",
    "plt.savefig(GRAPHICS_DIR / \"rbf_kta_opt_iris_learning_curve.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
